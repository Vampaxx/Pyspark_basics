{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOFZtKA8e0P8WvpWmKDw/5W",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vampaxx/Pyspark_basics/blob/main/union()_%26_unionAll().ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JmDfnbGhKcjJ",
        "outputId": "b41547a1-8198-4587-cb36-8b1e6cdbdaf9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.0.tar.gz (316.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.9/316.9 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.0-py2.py3-none-any.whl size=317425344 sha256=dabfa813bef55aa1b7b12dc1a6ea918f29e353b166253c41bbcb73362418c103\n",
            "  Stored in directory: /root/.cache/pip/wheels/41/4e/10/c2cf2467f71c678cfc8a6b9ac9241e5e44a01940da8fbb17fc\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.0\n"
          ]
        }
      ],
      "source": [
        "! pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import (StringType,StructField,\n",
        "                               StructType,IntegerType,\n",
        "                               ArrayType,MapType)\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "from pyspark.sql.functions import col,explode,split\n",
        "from pyspark.sql.functions import col,lit,when,expr\n",
        "\n"
      ],
      "metadata": {
        "id": "gslc0ly12DlR"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark  = SparkSession.builder.appName('union &unionAll').getOrCreate()"
      ],
      "metadata": {
        "id": "wEGBzwtG2E2I"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## union() & unionAll()\n",
        "\n",
        "- **union() & unionAll()** transformation are used to merge two ore more DataFrame's of same schema or structure\n",
        "\n",
        "- union() and unionAll() method merges two dataframes and return the new Dataframe with all rows from two Dataframes regardless of duplicate data.\n",
        "\n",
        "- To remove duplicates use distinct() function.\n"
      ],
      "metadata": {
        "id": "JaxhE_QZ2STI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data1 = [\n",
        "    (1,'Micheal','Male',2312,'IT'),\\\n",
        "    (2,'Jackson','Male',1245,'HR'),\\\n",
        "    (3,'Mithila','Female',1451,'HR'),\\\n",
        "    (3,'Mithila','Female',1451,'HR'),\\\n",
        "]\n",
        "data2 = [\n",
        "    (1,'Micheal','Male',2312,'IT'),\\\n",
        "    (4,'Daniel','Female',641,'R&D'),\\\n",
        "    (5,'Johnson','Male',5645,'Payroll')\n",
        "]\n",
        "\n",
        "schema = ['Emp_id','Emp_name','Gender','Salary','Department']\n",
        "\n",
        "df1 = spark.createDataFrame(data1,schema)\n",
        "df2 = spark.createDataFrame(data2,schema)"
      ],
      "metadata": {
        "id": "vXwDpjJr3TQ_"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.union(df2).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KX6yr2oW3lZR",
        "outputId": "491214f8-1cb8-4d73-9693-38e2a1995703"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+--------+------+------+----------+\n",
            "|Emp_id|Emp_name|Gender|Salary|Department|\n",
            "+------+--------+------+------+----------+\n",
            "|     1| Micheal|  Male|  2312|        IT|\n",
            "|     2| Jackson|  Male|  1245|        HR|\n",
            "|     3| Mithila|Female|  1451|        HR|\n",
            "|     3| Mithila|Female|  1451|        HR|\n",
            "|     1| Micheal|  Male|  2312|        IT|\n",
            "|     4|  Daniel|Female|   641|       R&D|\n",
            "|     5| Johnson|  Male|  5645|   Payroll|\n",
            "+------+--------+------+------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_df = df1.unionAll(df2)\n",
        "new_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cc-eOllR3rzx",
        "outputId": "bb8e02eb-7046-480d-f7e4-6978d222f742"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+--------+------+------+----------+\n",
            "|Emp_id|Emp_name|Gender|Salary|Department|\n",
            "+------+--------+------+------+----------+\n",
            "|     1| Micheal|  Male|  2312|        IT|\n",
            "|     2| Jackson|  Male|  1245|        HR|\n",
            "|     3| Mithila|Female|  1451|        HR|\n",
            "|     3| Mithila|Female|  1451|        HR|\n",
            "|     1| Micheal|  Male|  2312|        IT|\n",
            "|     4|  Daniel|Female|   641|       R&D|\n",
            "|     5| Johnson|  Male|  5645|   Payroll|\n",
            "+------+--------+------+------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- If we use ** unionAll() ** the result will include all rows from DataFrame including duplicates  ------>>>> Its in SQL\n",
        "\n",
        "- If we use ** union() ** the result only include distinct values from dataframes            ------>>>> Its in SQL\n",
        "\n",
        "- In PySpark, both functions perform the same operation; in each function, duplicates are not removed.\n"
      ],
      "metadata": {
        "id": "kZOMcuTc4I-g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## How to remove duplicate rows of datas from dataframes\n",
        "\n",
        "new_df.distinct().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "193GbA8j62W_",
        "outputId": "8d636cab-c95c-40c4-fdd2-690d57c59e7a"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+--------+------+------+----------+\n",
            "|Emp_id|Emp_name|Gender|Salary|Department|\n",
            "+------+--------+------+------+----------+\n",
            "|     2| Jackson|  Male|  1245|        HR|\n",
            "|     1| Micheal|  Male|  2312|        IT|\n",
            "|     3| Mithila|Female|  1451|        HR|\n",
            "|     4|  Daniel|Female|   641|       R&D|\n",
            "|     5| Johnson|  Male|  5645|   Payroll|\n",
            "+------+--------+------+------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KqJWaz0KFp-8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uzXAy0aA61JQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "quKGKl595224"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Px4qz2de3qRo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jByYdAzY3eni"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}