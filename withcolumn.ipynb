{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMwlBq/lNueceBbVIZWvApV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vampaxx/Pyspark_basics/blob/main/withcolumn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CoTHuouCr2XU",
        "outputId": "31ec8a72-77da-4976-85a3-32ca060a1ca2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.0.tar.gz (316.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.9/316.9 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.0-py2.py3-none-any.whl size=317425344 sha256=a23537a0426aaa2e9922e7cf560b5efd35d6d3088c773138ca4b594e17f153c8\n",
            "  Stored in directory: /root/.cache/pip/wheels/41/4e/10/c2cf2467f71c678cfc8a6b9ac9241e5e44a01940da8fbb17fc\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.0\n"
          ]
        }
      ],
      "source": [
        "! pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SRWTgzPOr297",
        "outputId": "cd2b4443-7cdb-4194-c59b-32f9fb9c8f69"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "csv_file = ('/content/drive/MyDrive/Pyspark/datas/Clean_Dataset.csv')"
      ],
      "metadata": {
        "id": "zoxtAtWrr4Na"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pyspark withcolumn() is a trasnformation function of dataframe which is used to change the value, convert the datatype of an existing column, create new column and many more"
      ],
      "metadata": {
        "id": "CHYyhgZVtWVj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col,lit,when\n",
        "\n",
        "# create session\n",
        "spark = SparkSession.builder.appName('withcolumn').getOrCreate()"
      ],
      "metadata": {
        "id": "LSiK2MzEu15T"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = [(1,'Shah',50000),\n",
        "        (2,'Micheal',75000),\n",
        "        (3,'Mia',10000),\n",
        "        (4,'Daniel',2500),\n",
        "        (5,'Johnson',6000)]\n",
        "columns = ['Id','Emp_name','Salary']\n",
        "df = spark.createDataFrame(data,schema = columns)\n",
        "df.show()\n",
        "df.count()\n",
        "df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jubnRgvatqQd",
        "outputId": "f2ab964b-57c9-44c1-d70a-3edd0a638df3"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+--------+------+\n",
            "| Id|Emp_name|Salary|\n",
            "+---+--------+------+\n",
            "|  1|    Shah| 50000|\n",
            "|  2| Micheal| 75000|\n",
            "|  3|     Mia| 10000|\n",
            "|  4|  Daniel|  2500|\n",
            "|  5| Johnson|  6000|\n",
            "+---+--------+------+\n",
            "\n",
            "root\n",
            " |-- Id: long (nullable = true)\n",
            " |-- Emp_name: string (nullable = true)\n",
            " |-- Salary: long (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.Id+2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yDUeFXeCl8AI",
        "outputId": "709af8b4-f59c-4bf2-87ce-dca07b68518e"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Column<'(Id + 2)'>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.show()\n",
        "df.withColumn(colName='Salary',col=col('Salary').cast('Integer')).printSchema()\n",
        "\n",
        "# change existing column value\n",
        "df.withColumn('Salary',col('Salary')*2).show()\n",
        "\n",
        "\n",
        "df.withColumn('Salary+Increament',col('Salary')+col('Salary')*0.1).show()\n",
        "\n",
        "df.withColumn('Department',lit('Production')).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_zsJqC0kmIlw",
        "outputId": "6d545ea4-b3c0-4dcb-ae2c-f5a1a5528216"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+--------+------+\n",
            "| Id|Emp_name|Salary|\n",
            "+---+--------+------+\n",
            "|  1|    Shah| 50000|\n",
            "|  2| Micheal| 75000|\n",
            "|  3|     Mia| 10000|\n",
            "|  4|  Daniel|  2500|\n",
            "|  5| Johnson|  6000|\n",
            "+---+--------+------+\n",
            "\n",
            "root\n",
            " |-- Id: long (nullable = true)\n",
            " |-- Emp_name: string (nullable = true)\n",
            " |-- Salary: integer (nullable = true)\n",
            "\n",
            "+---+--------+------+\n",
            "| Id|Emp_name|Salary|\n",
            "+---+--------+------+\n",
            "|  1|    Shah|100000|\n",
            "|  2| Micheal|150000|\n",
            "|  3|     Mia| 20000|\n",
            "|  4|  Daniel|  5000|\n",
            "|  5| Johnson| 12000|\n",
            "+---+--------+------+\n",
            "\n",
            "+---+--------+------+-----------------+\n",
            "| Id|Emp_name|Salary|Salary+Increament|\n",
            "+---+--------+------+-----------------+\n",
            "|  1|    Shah| 50000|          55000.0|\n",
            "|  2| Micheal| 75000|          82500.0|\n",
            "|  3|     Mia| 10000|          11000.0|\n",
            "|  4|  Daniel|  2500|           2750.0|\n",
            "|  5| Johnson|  6000|           6600.0|\n",
            "+---+--------+------+-----------------+\n",
            "\n",
            "+---+--------+------+----------+\n",
            "| Id|Emp_name|Salary|Department|\n",
            "+---+--------+------+----------+\n",
            "|  1|    Shah| 50000|Production|\n",
            "|  2| Micheal| 75000|Production|\n",
            "|  3|     Mia| 10000|Production|\n",
            "|  4|  Daniel|  2500|Production|\n",
            "|  5| Johnson|  6000|Production|\n",
            "+---+--------+------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = df.withColumn('Department',\n",
        "              when(col('Emp_name') == 'Mia',lit('Production'))\n",
        "              .when(col('Emp_name') == 'Daniel', lit('Data analyst'))\n",
        "              .when(col('Emp_name') == 'Johnson',lit('Data engineer'))\n",
        "              .otherwise(lit('Associate'))\n",
        "              )"
      ],
      "metadata": {
        "id": "Svu2R7zYpRnD"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gIWorxcUxfAs",
        "outputId": "a74fbb6b-37b0-4d6f-8f59-21454ca6cfaf"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+--------+------+-------------+\n",
            "| Id|Emp_name|Salary|   Department|\n",
            "+---+--------+------+-------------+\n",
            "|  1|    Shah| 50000|    Associate|\n",
            "|  2| Micheal| 75000|    Associate|\n",
            "|  3|     Mia| 10000|   Production|\n",
            "|  4|  Daniel|  2500| Data analyst|\n",
            "|  5| Johnson|  6000|Data engineer|\n",
            "+---+--------+------+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = df1.withColumn('working_hours',\n",
        "                      when(col('Department') == 'Associate',lit(10))\n",
        "                      .when(col('Department') == 'Production',lit(7))\n",
        "                      .when(col('Department') == 'Data analyst',lit(6))\n",
        "                      .when(col('Department') == 'Data engineer',lit(8))\n",
        "                      .otherwise(lit(None))\n",
        "                      )\n",
        "df2 = df2.withColumn(colName='Id',col=col('Id').cast('Integer'))"
      ],
      "metadata": {
        "id": "XO8Yk-wIuu30"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s1FQ8XVZxokt",
        "outputId": "9a873c6e-8d26-4a60-be7e-d160ee885d7e"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+--------+------+-------------+-------------+\n",
            "| Id|Emp_name|Salary|   Department|working_hours|\n",
            "+---+--------+------+-------------+-------------+\n",
            "|  1|    Shah| 50000|    Associate|           10|\n",
            "|  2| Micheal| 75000|    Associate|           10|\n",
            "|  3|     Mia| 10000|   Production|            7|\n",
            "|  4|  Daniel|  2500| Data analyst|            6|\n",
            "|  5| Johnson|  6000|Data engineer|            8|\n",
            "+---+--------+------+-------------+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df2.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dUSbTw4Oxpmt",
        "outputId": "07d4bd85-46ef-4f11-91d1-9b0851ab4f35"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Id: integer (nullable = true)\n",
            " |-- Emp_name: string (nullable = true)\n",
            " |-- Salary: long (nullable = true)\n",
            " |-- Department: string (nullable = false)\n",
            " |-- working_hours: integer (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import concat, lit\n",
        "\n",
        "df3 = df2.withColumn('Emp_department', concat(df2['Emp_name'], lit('--'), df2['Department']))\n",
        "df3.show(truncate=False)\n",
        "df3.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rVAHonGSyXIk",
        "outputId": "4cce4aed-4d1d-4f9d-c96a-8fb0fae37514"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+--------+------+-------------+-------------+----------------------+\n",
            "|Id |Emp_name|Salary|Department   |working_hours|Emp_department        |\n",
            "+---+--------+------+-------------+-------------+----------------------+\n",
            "|1  |Shah    |50000 |Associate    |10           |Shah--Associate       |\n",
            "|2  |Micheal |75000 |Associate    |10           |Micheal--Associate    |\n",
            "|3  |Mia     |10000 |Production   |7            |Mia--Production       |\n",
            "|4  |Daniel  |2500  |Data analyst |6            |Daniel--Data analyst  |\n",
            "|5  |Johnson |6000  |Data engineer|8            |Johnson--Data engineer|\n",
            "+---+--------+------+-------------+-------------+----------------------+\n",
            "\n",
            "root\n",
            " |-- Id: integer (nullable = true)\n",
            " |-- Emp_name: string (nullable = true)\n",
            " |-- Salary: long (nullable = true)\n",
            " |-- Department: string (nullable = false)\n",
            " |-- working_hours: integer (nullable = true)\n",
            " |-- Emp_department: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZwbQsESX020V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hLhcnqru0re9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "A6gW1F6d0d1l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0xQ38YEZwo01"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4bgPkob5o1nx"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5CP7vGZmoVZh"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "k7wtznc4jIEI"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nMS69EsXvKnz"
      },
      "execution_count": 27,
      "outputs": []
    }
  ]
}