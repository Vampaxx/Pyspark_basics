{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vampaxx/Pyspark_basics/blob/main/create_dataframe.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G_HZxQlR9gM4",
        "outputId": "c13cb634-5a30-4993-c403-01cafc34637e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.0.tar.gz (316.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.9/316.9 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.0-py2.py3-none-any.whl size=317425344 sha256=8fad9c5a71b19b7306e5504c520b5bc6109c0e24bc9ebb16973ed2c355a0e5ab\n",
            "  Stored in directory: /root/.cache/pip/wheels/41/4e/10/c2cf2467f71c678cfc8a6b9ac9241e5e44a01940da8fbb17fc\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.0\n"
          ]
        }
      ],
      "source": [
        "! pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "pCRh-lHauZ-E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19fb825b-9c53-4718-9464-15e171f70cf7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "TuniQDso9jLw"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "import numpy as np\n",
        "from pyspark.sql.functions import col,isnan, when, count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "cdm9j1Yu9oQA"
      },
      "outputs": [],
      "source": [
        "csv_file = ('/content/drive/MyDrive/Pyspark/datas/Clean_Dataset.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Drn7NxOl9uiH"
      },
      "outputs": [],
      "source": [
        "# create session\n",
        "spark = SparkSession.builder.appName('Missing_value').getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "nwQz_y1p9xY2"
      },
      "outputs": [],
      "source": [
        "df = spark.read.csv(csv_file,header=True,inferSchema=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-Trw3dtBCmv"
      },
      "source": [
        "## Another Methods"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "HuH6QAZkAFhV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e51279aa-658a-4616-91dd-995e199f61e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+---------+-------+-----------+--------------+-----+-------------+----------------+-------+--------+---------+-----+\n",
            "| _c0|      _c1|    _c2|        _c3|           _c4|  _c5|          _c6|             _c7|    _c8|     _c9|     _c10| _c11|\n",
            "+----+---------+-------+-----------+--------------+-----+-------------+----------------+-------+--------+---------+-----+\n",
            "|NULL|  airline| flight|source_city|departure_time|stops| arrival_time|destination_city|  class|duration|days_left|price|\n",
            "|   0| SpiceJet|SG-8709|      Delhi|       Evening| zero|        Night|          Mumbai|Economy|    2.17|        1| 5953|\n",
            "|   1| SpiceJet|SG-8157|      Delhi| Early_Morning| zero|      Morning|          Mumbai|Economy|    2.33|        1| 5953|\n",
            "|   2|  AirAsia| I5-764|      Delhi| Early_Morning| zero|Early_Morning|          Mumbai|Economy|    2.17|        1| 5956|\n",
            "|   3|  Vistara| UK-995|      Delhi|       Morning| zero|    Afternoon|          Mumbai|Economy|    2.25|        1| 5955|\n",
            "|   4|  Vistara| UK-963|      Delhi|       Morning| zero|      Morning|          Mumbai|Economy|    2.33|        1| 5955|\n",
            "|   5|  Vistara| UK-945|      Delhi|       Morning| zero|    Afternoon|          Mumbai|Economy|    2.33|        1| 5955|\n",
            "|   6|  Vistara| UK-927|      Delhi|       Morning| zero|      Morning|          Mumbai|Economy|    2.08|        1| 6060|\n",
            "|   7|  Vistara| UK-951|      Delhi|     Afternoon| zero|      Evening|          Mumbai|Economy|    2.17|        1| 6060|\n",
            "|   8| GO_FIRST| G8-334|      Delhi| Early_Morning| zero|      Morning|          Mumbai|Economy|    2.17|        1| 5954|\n",
            "|   9| GO_FIRST| G8-336|      Delhi|     Afternoon| zero|      Evening|          Mumbai|Economy|    2.25|        1| 5954|\n",
            "|  10| GO_FIRST| G8-392|      Delhi|     Afternoon| zero|      Evening|          Mumbai|Economy|    2.25|        1| 5954|\n",
            "|  11| GO_FIRST| G8-338|      Delhi|       Morning| zero|    Afternoon|          Mumbai|Economy|    2.33|        1| 5954|\n",
            "|  12|   Indigo|6E-5001|      Delhi| Early_Morning| zero|      Morning|          Mumbai|Economy|    2.17|        1| 5955|\n",
            "|  13|   Indigo|6E-6202|      Delhi|       Morning| zero|    Afternoon|          Mumbai|Economy|    2.17|        1| 5955|\n",
            "|  14|   Indigo| 6E-549|      Delhi|     Afternoon| zero|      Evening|          Mumbai|Economy|    2.25|        1| 5955|\n",
            "|  15|   Indigo|6E-6278|      Delhi|       Morning| zero|      Morning|          Mumbai|Economy|    2.33|        1| 5955|\n",
            "|  16|Air_India| AI-887|      Delhi| Early_Morning| zero|      Morning|          Mumbai|Economy|    2.08|        1| 5955|\n",
            "|  17|Air_India| AI-665|      Delhi| Early_Morning| zero|      Morning|          Mumbai|Economy|    2.17|        1| 5955|\n",
            "|  18|  AirAsia| I5-747|      Delhi|       Evening|  one|Early_Morning|          Mumbai|Economy|   12.25|        1| 5949|\n",
            "+----+---------+-------+-----------+--------------+-----+-------------+----------------+-------+--------+---------+-----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "spark.read.format('csv').load(csv_file).show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "OobmbZwkAYk0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2621d30c-150e-4e09-a830-bbd33c7509f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+---------+-------+-----------+--------------+-----+-------------+----------------+-------+--------+---------+-----+\n",
            "|_c0|  airline| flight|source_city|departure_time|stops| arrival_time|destination_city|  class|duration|days_left|price|\n",
            "+---+---------+-------+-----------+--------------+-----+-------------+----------------+-------+--------+---------+-----+\n",
            "|  0| SpiceJet|SG-8709|      Delhi|       Evening| zero|        Night|          Mumbai|Economy|    2.17|        1| 5953|\n",
            "|  1| SpiceJet|SG-8157|      Delhi| Early_Morning| zero|      Morning|          Mumbai|Economy|    2.33|        1| 5953|\n",
            "|  2|  AirAsia| I5-764|      Delhi| Early_Morning| zero|Early_Morning|          Mumbai|Economy|    2.17|        1| 5956|\n",
            "|  3|  Vistara| UK-995|      Delhi|       Morning| zero|    Afternoon|          Mumbai|Economy|    2.25|        1| 5955|\n",
            "|  4|  Vistara| UK-963|      Delhi|       Morning| zero|      Morning|          Mumbai|Economy|    2.33|        1| 5955|\n",
            "|  5|  Vistara| UK-945|      Delhi|       Morning| zero|    Afternoon|          Mumbai|Economy|    2.33|        1| 5955|\n",
            "|  6|  Vistara| UK-927|      Delhi|       Morning| zero|      Morning|          Mumbai|Economy|    2.08|        1| 6060|\n",
            "|  7|  Vistara| UK-951|      Delhi|     Afternoon| zero|      Evening|          Mumbai|Economy|    2.17|        1| 6060|\n",
            "|  8| GO_FIRST| G8-334|      Delhi| Early_Morning| zero|      Morning|          Mumbai|Economy|    2.17|        1| 5954|\n",
            "|  9| GO_FIRST| G8-336|      Delhi|     Afternoon| zero|      Evening|          Mumbai|Economy|    2.25|        1| 5954|\n",
            "| 10| GO_FIRST| G8-392|      Delhi|     Afternoon| zero|      Evening|          Mumbai|Economy|    2.25|        1| 5954|\n",
            "| 11| GO_FIRST| G8-338|      Delhi|       Morning| zero|    Afternoon|          Mumbai|Economy|    2.33|        1| 5954|\n",
            "| 12|   Indigo|6E-5001|      Delhi| Early_Morning| zero|      Morning|          Mumbai|Economy|    2.17|        1| 5955|\n",
            "| 13|   Indigo|6E-6202|      Delhi|       Morning| zero|    Afternoon|          Mumbai|Economy|    2.17|        1| 5955|\n",
            "| 14|   Indigo| 6E-549|      Delhi|     Afternoon| zero|      Evening|          Mumbai|Economy|    2.25|        1| 5955|\n",
            "| 15|   Indigo|6E-6278|      Delhi|       Morning| zero|      Morning|          Mumbai|Economy|    2.33|        1| 5955|\n",
            "| 16|Air_India| AI-887|      Delhi| Early_Morning| zero|      Morning|          Mumbai|Economy|    2.08|        1| 5955|\n",
            "| 17|Air_India| AI-665|      Delhi| Early_Morning| zero|      Morning|          Mumbai|Economy|    2.17|        1| 5955|\n",
            "| 18|  AirAsia| I5-747|      Delhi|       Evening|  one|Early_Morning|          Mumbai|Economy|   12.25|        1| 5949|\n",
            "| 19|  AirAsia| I5-747|      Delhi|       Evening|  one|      Morning|          Mumbai|Economy|   16.33|        1| 5949|\n",
            "+---+---------+-------+-----------+--------------+-----+-------------+----------------+-------+--------+---------+-----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# read with header\n",
        "spark.read.option(\"header\",True)\\\n",
        ".option(\"inferSchema\", \"true\")\\\n",
        ".csv(csv_file).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "wXhfyRtbv-Hx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "515e66ea-106b-4a45-cb97-c9fc706d8a59"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+---------+-------+-----------+--------------+-----+-------------+----------------+-------+--------+---------+-----+\n",
            "| Id|  airline| flight|source_city|departure_time|stops| arrival_time|destination_city|  class|duration|days_left|price|\n",
            "+---+---------+-------+-----------+--------------+-----+-------------+----------------+-------+--------+---------+-----+\n",
            "|  0| SpiceJet|SG-8709|      Delhi|       Evening| zero|        Night|          Mumbai|Economy|    2.17|        1| 5953|\n",
            "|  1| SpiceJet|SG-8157|      Delhi| Early_Morning| zero|      Morning|          Mumbai|Economy|    2.33|        1| 5953|\n",
            "|  2|  AirAsia| I5-764|      Delhi| Early_Morning| zero|Early_Morning|          Mumbai|Economy|    2.17|        1| 5956|\n",
            "|  3|  Vistara| UK-995|      Delhi|       Morning| zero|    Afternoon|          Mumbai|Economy|    2.25|        1| 5955|\n",
            "|  4|  Vistara| UK-963|      Delhi|       Morning| zero|      Morning|          Mumbai|Economy|    2.33|        1| 5955|\n",
            "|  5|  Vistara| UK-945|      Delhi|       Morning| zero|    Afternoon|          Mumbai|Economy|    2.33|        1| 5955|\n",
            "|  6|  Vistara| UK-927|      Delhi|       Morning| zero|      Morning|          Mumbai|Economy|    2.08|        1| 6060|\n",
            "|  7|  Vistara| UK-951|      Delhi|     Afternoon| zero|      Evening|          Mumbai|Economy|    2.17|        1| 6060|\n",
            "|  8| GO_FIRST| G8-334|      Delhi| Early_Morning| zero|      Morning|          Mumbai|Economy|    2.17|        1| 5954|\n",
            "|  9| GO_FIRST| G8-336|      Delhi|     Afternoon| zero|      Evening|          Mumbai|Economy|    2.25|        1| 5954|\n",
            "| 10| GO_FIRST| G8-392|      Delhi|     Afternoon| zero|      Evening|          Mumbai|Economy|    2.25|        1| 5954|\n",
            "| 11| GO_FIRST| G8-338|      Delhi|       Morning| zero|    Afternoon|          Mumbai|Economy|    2.33|        1| 5954|\n",
            "| 12|   Indigo|6E-5001|      Delhi| Early_Morning| zero|      Morning|          Mumbai|Economy|    2.17|        1| 5955|\n",
            "| 13|   Indigo|6E-6202|      Delhi|       Morning| zero|    Afternoon|          Mumbai|Economy|    2.17|        1| 5955|\n",
            "| 14|   Indigo| 6E-549|      Delhi|     Afternoon| zero|      Evening|          Mumbai|Economy|    2.25|        1| 5955|\n",
            "| 15|   Indigo|6E-6278|      Delhi|       Morning| zero|      Morning|          Mumbai|Economy|    2.33|        1| 5955|\n",
            "| 16|Air_India| AI-887|      Delhi| Early_Morning| zero|      Morning|          Mumbai|Economy|    2.08|        1| 5955|\n",
            "| 17|Air_India| AI-665|      Delhi| Early_Morning| zero|      Morning|          Mumbai|Economy|    2.17|        1| 5955|\n",
            "| 18|  AirAsia| I5-747|      Delhi|       Evening|  one|Early_Morning|          Mumbai|Economy|   12.25|        1| 5949|\n",
            "| 19|  AirAsia| I5-747|      Delhi|       Evening|  one|      Morning|          Mumbai|Economy|   16.33|        1| 5949|\n",
            "+---+---------+-------+-----------+--------------+-----+-------------+----------------+-------+--------+---------+-----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# read with header\n",
        "spark.read.option(\"header\",True)\\\n",
        ".option(\"inferSchema\", \"true\")\\\n",
        ".csv(csv_file).withColumnRenamed(\"_c0\",'Id').show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_CGxRdV_MaZ"
      },
      "source": [
        "## Method 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "3Gh2gguS-l35"
      },
      "outputs": [],
      "source": [
        "data = [(1,'arjun'),\n",
        "        (2,'micheal'),\n",
        "        (3,'mia'),\n",
        "        (4,'jackson'),\n",
        "        (5,'khalifa')]\n",
        "schema = ['Emp_no','Name']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "fN_7gnh7-y9Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c975382-3454-43d6-fab6-6868e687cb44"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-------+\n",
            "|Emp_no|   Name|\n",
            "+------+-------+\n",
            "|     1|  arjun|\n",
            "|     2|micheal|\n",
            "|     3|    mia|\n",
            "|     4|jackson|\n",
            "|     5|khalifa|\n",
            "+------+-------+\n",
            "\n",
            "root\n",
            " |-- Emp_no: long (nullable = true)\n",
            " |-- Name: string (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df = spark.createDataFrame(data,schema)\n",
        "df.show()\n",
        "df.printSchema()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o5CoJAIC_QQ4"
      },
      "source": [
        "## Method 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "bQv5Gujo_R6e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a28a29c8-8a48-480f-d8ce-ba2f4b551f09"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+---+\n",
            "|   Name| id|\n",
            "+-------+---+\n",
            "|  Arjun|  1|\n",
            "|Micheal|  2|\n",
            "+-------+---+\n",
            "\n",
            "root\n",
            " |-- Name: string (nullable = true)\n",
            " |-- id: long (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "data = [{'id':1, 'Name':'Arjun'},\n",
        "        {'id':2, 'Name':'Micheal'}]\n",
        "df = spark.createDataFrame(data)\n",
        "df.show()\n",
        "df.printSchema()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CDUYnycjAAYA"
      },
      "source": [
        "## Method 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "wrJHS6CRquS5"
      },
      "outputs": [],
      "source": [
        "## Create a DataFrame with the explicit schema specified.\n",
        "\n",
        "from pyspark.sql.types import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "QIdi8kCJsG5A"
      },
      "outputs": [],
      "source": [
        "data = [(1,'arjun'),\n",
        "        (2,'micheal'),\n",
        "        (3,'mia'),\n",
        "        (4,'jackson'),\n",
        "        (5,'khalifa')]\n",
        "schema = StructType([\n",
        "    StructField(\"Emp_no\", IntegerType(), True),\n",
        "    StructField(\"Name\",   StringType(), True)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "iZzkH1cNrhJx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1b424ce-0c0a-4f8d-b883-dc2a81555f60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Emp_no: integer (nullable = true)\n",
            " |-- Name: string (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "spark.createDataFrame(data,schema).printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "SgaD92NbqS44",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1fb64bc4-0adf-4113-e278-a2bf8916375a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(Emp_no=1, Name='arjun'),\n",
              " Row(Emp_no=2, Name='micheal'),\n",
              " Row(Emp_no=3, Name='mia'),\n",
              " Row(Emp_no=4, Name='jackson'),\n",
              " Row(Emp_no=5, Name='khalifa')]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "spark.createDataFrame(data,schema).collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "OLFmSwgM-7b4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f777e66-793b-402f-96c7-d7e30a71cfac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+--------+-------+-----------+--------------+-----+-------------+----------------+-------+--------+---------+-----+\n",
            "| Id| airline| flight|source_city|departure_time|stops| arrival_time|destination_city|  class|duration|days_left|price|\n",
            "+---+--------+-------+-----------+--------------+-----+-------------+----------------+-------+--------+---------+-----+\n",
            "|  0|SpiceJet|SG-8709|      Delhi|       Evening| zero|        Night|          Mumbai|Economy|    2.17|        1| 5953|\n",
            "|  1|SpiceJet|SG-8157|      Delhi| Early_Morning| zero|      Morning|          Mumbai|Economy|    2.33|        1| 5953|\n",
            "|  2| AirAsia| I5-764|      Delhi| Early_Morning| zero|Early_Morning|          Mumbai|Economy|    2.17|        1| 5956|\n",
            "|  3| Vistara| UK-995|      Delhi|       Morning| zero|    Afternoon|          Mumbai|Economy|    2.25|        1| 5955|\n",
            "|  4| Vistara| UK-963|      Delhi|       Morning| zero|      Morning|          Mumbai|Economy|    2.33|        1| 5955|\n",
            "+---+--------+-------+-----------+--------------+-----+-------------+----------------+-------+--------+---------+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "spark.read.format('csv')\\\n",
        ".option(key='header',value=True)\\\n",
        ".load(csv_file)\\\n",
        ".withColumnRenamed('_c0','Id').show(5)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MCVUXQgsV3HK"
      },
      "source": [
        "## read multiple csv files from different folders and if inferschema is same for both files\n",
        "file_path = [path_1,path_2]\n",
        "\n",
        "spark.read.csv(file_path,header=True).show()\n",
        "\n",
        "## if all csv files are in same folder then we use\n",
        "file_path = 'folder/folder_of_files/'\n",
        "\n",
        "spark.read.csv(file_path,header=True).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "7Pc0IIvaWQlf"
      },
      "outputs": [],
      "source": [
        "# read with header\n",
        "df = spark.read.option(\"header\",True)\\\n",
        "    .option(\"inferSchema\", \"true\")\\\n",
        "    .csv(csv_file).withColumnRenamed(\"_c0\",'Id')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.read.csv(csv_file,header=True,inferSchema=False)"
      ],
      "metadata": {
        "id": "gB2176ZimFTr"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "Y3Oa0fbfW_8Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ac3542c-85ea-443e-e090-9f12e71000ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- _c0: string (nullable = true)\n",
            " |-- airline: string (nullable = true)\n",
            " |-- flight: string (nullable = true)\n",
            " |-- source_city: string (nullable = true)\n",
            " |-- departure_time: string (nullable = true)\n",
            " |-- stops: string (nullable = true)\n",
            " |-- arrival_time: string (nullable = true)\n",
            " |-- destination_city: string (nullable = true)\n",
            " |-- class: string (nullable = true)\n",
            " |-- duration: string (nullable = true)\n",
            " |-- days_left: string (nullable = true)\n",
            " |-- price: string (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "categorical_features = [col for col,data_type in df.dtypes if data_type =='string']\n",
        "numerical_features   = [col for col,data_type in df.dtypes if data_type == 'int']"
      ],
      "metadata": {
        "id": "HUv2OSs5hQ2k"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "[col for col,data_type in df.dtypes if data_type == 'int']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Flicv9Hp-_s",
        "outputId": "5e7a5fbc-c76d-479d-87a8-2d459fb7df3f"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "PgKn-9v9XMRX"
      },
      "outputs": [],
      "source": [
        "#here every column is string type, so we need to change the data type\n",
        "from pyspark.sql.types import *"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "schema = StructType().add(field='Id',data_type = IntegerType())\\\n",
        "                     .add(field='airline',data_type = StringType())\\\n",
        "                     .add(field='flight',data_type = StringType())\\\n",
        "                     .add(field='source_city',data_type = StringType())\\\n",
        "                     .add(field='departure_time',data_type = StringType())\\\n",
        "                     .add(field='stops',data_type = StringType())\\\n",
        "                     .add(field='arrival_time',data_type = StringType())\\\n",
        "                     .add(field='destination_city',data_type = StringType())\\\n",
        "                     .add(field='class',data_type = StringType())\\\n",
        "                     .add(field='days_left',data_type = IntegerType())\\\n",
        "                     .add(field='price',data_type = IntegerType())"
      ],
      "metadata": {
        "id": "3nNc0lE0jInt"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "0cusK1DbR2o4"
      },
      "outputs": [],
      "source": [
        "df = spark.read.csv(csv_file,schema=schema,header=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6QRG06MIlCYU",
        "outputId": "06e3d9d2-7398-4e47-ede4-f6fe67dd7574"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Id: integer (nullable = true)\n",
            " |-- airline: string (nullable = true)\n",
            " |-- flight: string (nullable = true)\n",
            " |-- source_city: string (nullable = true)\n",
            " |-- departure_time: string (nullable = true)\n",
            " |-- stops: string (nullable = true)\n",
            " |-- arrival_time: string (nullable = true)\n",
            " |-- destination_city: string (nullable = true)\n",
            " |-- class: string (nullable = true)\n",
            " |-- days_left: integer (nullable = true)\n",
            " |-- price: integer (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_field = []\n",
        "\n",
        "for col in df.columns:\n",
        "\n",
        "  if col in categorical_features:\n",
        "    new_field.append(StructField(name=col,dataType=StringType()))\n",
        "\n",
        "  if col in numerical_features:\n",
        "    new_field.append(StructField(name=col,dataType=IntegerType()))\n",
        "\n",
        "\n",
        "new_schema = StructType(new_field)\n",
        "spark.read.csv(csv_file,schema=new_schema,header=True).printSchema()"
      ],
      "metadata": {
        "id": "JLOmUyaAlEnN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67b56624-3c0d-47a2-d27f-0d493a276e93"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- airline: string (nullable = true)\n",
            " |-- flight: string (nullable = true)\n",
            " |-- source_city: string (nullable = true)\n",
            " |-- departure_time: string (nullable = true)\n",
            " |-- stops: string (nullable = true)\n",
            " |-- arrival_time: string (nullable = true)\n",
            " |-- destination_city: string (nullable = true)\n",
            " |-- class: string (nullable = true)\n",
            " |-- days_left: string (nullable = true)\n",
            " |-- price: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "FFDBbY9BxI5h"
      },
      "outputs": [],
      "source": [
        "# df.write.parquet(\"airline_parquet_file.parquet\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "LCOPDGDa-0IH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Show()"
      ],
      "metadata": {
        "id": "lzbvfTecl6ks"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NUEigMcBmIvc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "URL1kYTb-l6v"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "468b7gO5-mFy"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "Fbgz75ef-mOn"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "P0pbKhe0-mRf"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1XaXWZi5vKMAh71KnXe39sa6E4ixlnsMK",
      "authorship_tag": "ABX9TyOpHmtZkIFnaVVtzPVK9OT5",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}